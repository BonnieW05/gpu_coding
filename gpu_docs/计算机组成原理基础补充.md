# 计算机组成原理基础补充

### 1.2 内存层次结构

```
CPU寄存器 (最快，容量最小)
    ↓
L1缓存 (很快，容量小)
    ↓
L2缓存 (较快，容量中等)
    ↓
L3缓存 (较慢，容量较大)
    ↓
主内存 (慢，容量大)
    ↓
存储设备 (最慢，容量最大)
```

---

## 2. GPU架构详解（45分钟）

### 2.1 GPU整体架构

```
GPU
├── SM (Streaming Multiprocessor) - 流式多处理器
│   ├── CUDA Core (计算核心)
│   ├── Shared Memory (共享内存)
│   ├── Register File (寄存器文件)
│   └── Warp Scheduler (线程束调度器)
├── Global Memory (全局内存)
├── L2 Cache (二级缓存)
└── Memory Controller (内存控制器)
```

### 2.2 核心概念解释

#### SM (Streaming Multiprocessor)
- **作用**：GPU的基本计算单元
- **数量**：4090有128个SM
- **功能**：执行实际的并行计算

#### Warp（线程束）
- **定义**：32个线程的集合
- **重要性**：GPU调度的基本单位
- **执行方式**：所有32个线程同时执行相同指令
- **比喻**：就像32个人同时做同样的动作

#### Block（线程块）
- **定义**：多个warp的集合
- **特点**：
  - 同一个block内的线程可以协作
  - 共享shared memory
  - 可以同步执行

#### Grid（网格）
- **定义**：多个block的集合
- **作用**：组织整个计算任务

### 2.3 内存类型详解

#### Global Memory（全局内存）
- **特点**：所有线程都可以访问
- **容量**：大（4090有24GB）
- **速度**：相对较慢
- **用途**：存储输入数据和输出结果

#### Shared Memory（共享内存）
- **特点**：block内线程共享
- **容量**：小（通常几十KB）
- **速度**：很快
- **用途**：临时存储，减少全局内存访问

#### Registers（寄存器）
- **特点**：每个线程私有
- **容量**：很小
- **速度**：最快
- **用途**：存储临时变量

---

## 3. 并行计算模式

### 3.1 SIMD vs SIMT

#### SIMD (Single Instruction, Multiple Data)
- **定义**：单指令多数据
- **特点**：所有处理单元执行相同指令，处理不同数据
- **例子**：向量加法 `[1,2,3] + [4,5,6] = [5,7,9]`

#### SIMT (Single Instruction, Multiple Thread)
- **定义**：单指令多线程
- **特点**：GPU使用的模式，比SIMD更灵活
- **优势**：可以处理分支和条件语句

### 3.2 并行计算的优势

**为什么GPU比CPU快？**
1. **并行度**：GPU有数千个核心，CPU只有几十个
2. **内存带宽**：GPU有更高的内存带宽
3. **专用设计**：针对并行计算优化

**什么时候GPU更快？**
- 大量简单重复的计算
- 数据并行性高的任务
- 矩阵运算、图像处理、深度学习

**什么时候CPU更快？**
- 复杂的逻辑判断
- 串行计算
- 小数据量的计算

---

## 4. GPU编程模型（45分钟）

### 4.1 线程组织层次

```
Grid (网格)
├── Block 0
│   ├── Warp 0 (线程 0-31)
│   ├── Warp 1 (线程 32-63)
│   └── ...
├── Block 1
│   ├── Warp 0 (线程 0-31)
│   └── ...
└── ...
```

### 4.2 线程索引

**一维情况**：
- `threadIdx.x`：线程在block内的索引
- `blockIdx.x`：block在grid内的索引
- `blockDim.x`：block的大小
- `gridDim.x`：grid的大小

**全局线程ID计算**：
```cuda
int globalId = blockIdx.x * blockDim.x + threadIdx.x;
```

### 4.3 内存访问模式

#### Coalesced Access（合并访问）
- **定义**：连续线程访问连续内存地址
- **优势**：高效利用内存带宽
- **例子**：线程0访问地址0，线程1访问地址1，...

#### Strided Access（跨步访问）
- **定义**：线程访问不连续的内存地址
- **劣势**：内存带宽利用率低
- **例子**：线程0访问地址0，线程1访问地址100，...

---

## 5. 性能优化基础（30分钟）

### 5.1 内存带宽 vs 计算能力

**内存带宽限制**：
- 数据传输速度限制
- 解决方案：减少内存访问，使用共享内存

**计算能力限制**：
- 计算速度限制
- 解决方案：提高计算密度，使用tensor core

### 5.2 常见优化策略

#### Tiling（分块）
- **目的**：将大问题分解为小块
- **优势**：提高缓存命中率
- **例子**：矩阵乘法分块

#### Memory Coalescing（内存合并）
- **目的**：优化内存访问模式
- **方法**：确保连续线程访问连续内存

#### Shared Memory使用
- **目的**：减少全局内存访问
- **方法**：将数据加载到共享内存

---

## 6. 实践理解（30分钟）

### 6.1 用代码理解概念

```python
import torch

# 创建测试数据
size = 1000
a = torch.randn(size, size, device='cuda')
b = torch.randn(size, size, device='cuda')

# 矩阵乘法 - 这是GPU最擅长的操作
c = torch.mm(a, b)  # 每个元素的计算都是独立的，高度并行

# 查看GPU信息
print(f"GPU名称: {torch.cuda.get_device_name(0)}")
print(f"GPU显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
print(f"SM数量: {torch.cuda.get_device_properties(0).multi_processor_count}")
```

### 6.2 理解并行性

```python
# 向量加法 - 每个元素独立计算
def vector_add_cpu(a, b):
    result = []
    for i in range(len(a)):
        result.append(a[i] + b[i])  # 串行计算
    return result

# GPU版本 - 所有元素同时计算
def vector_add_gpu(a, b):
    return a + b  # 并行计算，所有元素同时处理
```

---

## 7. 学习建议

### 7.1 学习顺序
1. **先理解概念**：不要急于写代码
2. **动手实践**：用简单例子验证理解
3. **逐步深入**：从简单kernel开始
4. **性能分析**：学会使用profiler

### 7.2 推荐资源
1. **NVIDIA CUDA编程指南**：官方权威文档
2. **YouTube视频**：搜索"GPU Architecture Explained"
3. **在线课程**：NVIDIA DLI免费课程
4. **实践项目**：从简单kernel开始

### 7.3 常见误区
1. **过度优化**：先确保正确性，再考虑性能
2. **忽视内存**：内存访问往往是瓶颈
3. **不理解硬件**：了解硬件限制很重要
4. **急于求成**：GPU编程需要时间积累

---

## 8. 下一步

现在你已经了解了GPU编程的基础概念，可以开始：

1. **运行环境检查脚本**：验证你的4090环境
2. **开始PyTorch学习**：从简单的GPU操作开始
3. **逐步深入Triton**：学习编写自定义kernel
4. **实践项目**：完成一个端到端的GPU加速项目

记住：GPU编程是一个实践性很强的领域，多动手、多实验、多分析性能，才能真正掌握。
