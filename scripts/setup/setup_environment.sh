#!/bin/bash

# GPUç¼–ç¨‹ç¯å¢ƒè®¾ç½®è„šæœ¬
# è‡ªåŠ¨å®‰è£…å’Œé…ç½®PyTorchã€Tritonã€ThunderKittenç­‰ä¾èµ–

set -e

echo "ğŸš€ å¼€å§‹è®¾ç½®GPUç¼–ç¨‹å­¦ä¹ ç¯å¢ƒ..."

# æ£€æŸ¥Pythonç‰ˆæœ¬
echo "ğŸ æ£€æŸ¥Pythonç‰ˆæœ¬..."
python_version=$(python3 --version 2>&1 | cut -d' ' -f2 | cut -d'.' -f1,2)
echo "Pythonç‰ˆæœ¬: $python_version"

if [[ $(echo "$python_version < 3.8" | bc -l) -eq 1 ]]; then
    echo "âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦3.8+"
    exit 1
fi

# æ£€æŸ¥CUDA
echo "ğŸ” æ£€æŸ¥CUDAç¯å¢ƒ..."
if command -v nvcc &> /dev/null; then
    cuda_version=$(nvcc --version | grep "release" | cut -d' ' -f6 | cut -d',' -f1)
    echo "âœ… CUDAç‰ˆæœ¬: $cuda_version"
else
    echo "âš ï¸  CUDAæœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨"
fi

# æ£€æŸ¥GPU
echo "ğŸ–¥ï¸  æ£€æŸ¥GPU..."
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits
else
    echo "âš ï¸  nvidia-smiæœªæ‰¾åˆ°ï¼Œå¯èƒ½æ²¡æœ‰NVIDIA GPU"
fi

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo "ğŸ“¦ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ..."
if [ ! -d "venv" ]; then
    python3 -m venv venv
    echo "âœ… è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º"
else
    echo "âœ… è™šæ‹Ÿç¯å¢ƒå·²å­˜åœ¨"
fi

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
echo "ğŸ”§ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ..."
source venv/bin/activate

# å‡çº§pip
echo "â¬†ï¸  å‡çº§pip..."
pip install --upgrade pip

# å®‰è£…PyTorch
echo "ğŸ”¥ å®‰è£…PyTorch..."
if command -v nvcc &> /dev/null; then
    # æœ‰CUDAï¼Œå®‰è£…CUDAç‰ˆæœ¬
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
else
    # æ— CUDAï¼Œå®‰è£…CPUç‰ˆæœ¬
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
fi

# å®‰è£…Triton
echo "âš¡ å®‰è£…Triton..."
pip install triton

# å®‰è£…ThunderKitten (å¦‚æœå¯ç”¨)
echo "ğŸ± å°è¯•å®‰è£…ThunderKitten..."
pip install thunderkitten || echo "âš ï¸  ThunderKittenå®‰è£…å¤±è´¥ï¼Œå¯èƒ½æš‚ä¸å¯ç”¨"

# å®‰è£…å…¶ä»–ä¾èµ–
echo "ğŸ“š å®‰è£…å…¶ä»–ä¾èµ–..."
pip install -r requirements.txt

# éªŒè¯å®‰è£…
echo "âœ… éªŒè¯å®‰è£…..."
python3 -c "
import torch
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    print(f'GPUåç§°: {torch.cuda.get_device_name()}')

try:
    import triton
    print(f'Tritonç‰ˆæœ¬: {triton.__version__}')
except ImportError:
    print('Tritonæœªå®‰è£…')

try:
    import thunderkitten
    print('ThunderKittenå·²å®‰è£…')
except ImportError:
    print('ThunderKittenæœªå®‰è£…')
"

echo ""
echo "ğŸ‰ ç¯å¢ƒè®¾ç½®å®Œæˆ!"
echo ""
echo "ğŸ“ ä½¿ç”¨æ–¹æ³•:"
echo "  source venv/bin/activate  # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ"
echo "  python pytorch/basics/01_tensor_basics.py  # è¿è¡ŒPyTorchç¤ºä¾‹"
echo "  python triton/basics/01_vector_add.py  # è¿è¡ŒTritonç¤ºä¾‹"
echo "  python shared/utils/device_utils.py  # æŸ¥çœ‹GPUä¿¡æ¯"
echo ""
echo "ğŸ”§ ç¼–è¯‘CUDAç¤ºä¾‹:"
echo "  nvcc -o hello_cuda cuda/basics/01_hello_cuda.cu"
echo "  ./hello_cuda"
